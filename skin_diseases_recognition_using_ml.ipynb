{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StankovicStevan/Master-s-Thesis-skin-diseases-detection-using-DL/blob/master/skin_diseases_recognition_using_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF_VAHxS9ZtT"
      },
      "source": [
        "**Data analysis & engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3EG7QF5sQ1F"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXqAXSej95Ry"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTNsEebg-x8e"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"kaggle_username\",\"key\":\"kaggle_key\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/skin_diseases_recognition_using_ml\n",
        "!mkdir /content/skin_diseases_recognition_using_ml/data"
      ],
      "metadata": {
        "id": "v7Inw_WnCeka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -av /content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model /content/skin_diseases_recognition_using_ml/data/final_data_for_training_model"
      ],
      "metadata": {
        "id": "66vi5INoctQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp5vJ7s_-FFt"
      },
      "outputs": [],
      "source": [
        "from kaggle.api.kaggle_api_extended import KaggleApi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNLRy4r5BiZz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgXSMvpNGhr6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "id": "mlLqWpbuRMIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys8RjU4RIM9m"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import plot_model\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "from tensorflow import Tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "rS96Nh-GbMWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If it is needed to connect to TPU run this cell:**"
      ],
      "metadata": {
        "id": "04LoDZfqDN4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "fp1OftXBDXGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TF_MASTER=''\n",
        "\n",
        "tpu_address = TF_MASTER"
      ],
      "metadata": {
        "id": "jXWxfsd4YA5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpu_address"
      ],
      "metadata": {
        "id": "d7-fHmMCYvLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "print(\"Number of devices: \", len(tf.config.list_logical_devices('TPU')))"
      ],
      "metadata": {
        "id": "WFcF4j2hYzts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "LSTlV1DAaESd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "metadata": {
        "id": "yLw5dRlfLneP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(tpu)"
      ],
      "metadata": {
        "id": "xUGHZ5MyLpio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Select appropriate distribution strategy\n",
        "# if tpu:\n",
        "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# else:\n",
        "#   strategy = tf.distribute.get_strategy() # Default strategy that works on CPU and single GPU\n",
        "#   print('Running on CPU instead')\n"
      ],
      "metadata": {
        "id": "094gwE3HLxvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhcfRsQFthsm"
      },
      "outputs": [],
      "source": [
        "def download_data_from_kaggle():\n",
        "    \"\"\"\n",
        "    This function download data from kaggle source and creates new file.\n",
        "\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    api = KaggleApi()\n",
        "\n",
        "    # API token has been provided through environment variables (KAGGLE_USERNAME, KAGGLE_KEY)\n",
        "    api.authenticate()\n",
        "\n",
        "    dataset = 'kmader/skin-cancer-mnist-ham10000'\n",
        "    file_name = 'HAM10000_metadata.csv'\n",
        "    file_path = '/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/input/'\n",
        "    dataset_dir = file_path + file_name\n",
        "    new_file_name = file_path + 'input_data_from_kaggle.csv'\n",
        "\n",
        "    # Checking whether file already is downloaded\n",
        "    if os.path.exists(new_file_name):\n",
        "        print(\"Found dataset directory, exiting\")\n",
        "        exit(0)\n",
        "\n",
        "    print(\"Dataset not found, using kaggle-api tool for download\")\n",
        "\n",
        "    # Downloading file from kaggle (link: 'https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000') and\n",
        "    # creating new file\n",
        "    api.dataset_download_files(dataset=dataset,\n",
        "                               path='/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/input',\n",
        "                               unzip=True)\n",
        "\n",
        "    # Renaming downloaded file\n",
        "    os.rename(dataset_dir, new_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjglTAPh9_hP"
      },
      "outputs": [],
      "source": [
        "download_data_from_kaggle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c33keurm-Bl8"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/skin_diseases_recognition_using_ml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFW2tzxHBHwS"
      },
      "source": [
        "**Data analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09kmu75VBJPa"
      },
      "outputs": [],
      "source": [
        "input_data = pd.read_csv(\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/input/input_data_from_kaggle.csv\",\n",
        "                             header=0,\n",
        "                             index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzRHEwAGBfpE"
      },
      "outputs": [],
      "source": [
        "input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMiS0Bw1CC0K"
      },
      "outputs": [],
      "source": [
        "def data_analysis(input_data):\n",
        "    \"\"\"\n",
        "    This function creates analysis of input data.\n",
        "\n",
        "    :param input_data: dataframe to be processed\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Columns are: {input_data.columns}\")\n",
        "\n",
        "    dx_unique = pd.unique(input_data['dx'])\n",
        "    print(f\"Unique dx: {dx_unique}\")\n",
        "\n",
        "    dx_type_unique = pd.unique(input_data['dx_type'])\n",
        "    print(f\"Unique dx_type: {dx_type_unique}\")\n",
        "\n",
        "    age_unique = pd.unique(input_data['age'])\n",
        "    print(f\"Unique age: {len(age_unique)}\")\n",
        "\n",
        "    sex_unique = pd.unique(input_data['sex'])\n",
        "    print(f\"Unique sex: {sex_unique}\")\n",
        "\n",
        "    localization_unique = pd.unique(input_data['localization'])\n",
        "    print(f\"Unique localization: {localization_unique}\")\n",
        "\n",
        "    id_unknown_sex = pd.unique(input_data[input_data['sex'] == 'unknown']['image_id'])\n",
        "    id_unknown_localization = pd.unique(input_data[input_data['localization'] == 'unknown']['image_id'])\n",
        "    print(f\"Unknown sex: {len(input_data[input_data['sex'] == 'unknown'])}\")\n",
        "    print(f\"Unknown sex ids: {id_unknown_sex}\")\n",
        "\n",
        "    print(f\"Unknown localization: {len(input_data[input_data['localization'] == 'unknown'])}\")\n",
        "    print(f\"Unknown localization ids: {id_unknown_localization}\")\n",
        "\n",
        "    same_unknown_ids = np.intersect1d(id_unknown_sex, id_unknown_localization)\n",
        "    print(f\"Same unknown ids: {len(same_unknown_ids)}\")\n",
        "\n",
        "    print(f\"Analysis:\\n{input_data.isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7duYxH3BBsss"
      },
      "outputs": [],
      "source": [
        "data_analysis(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5VmRhJ_DCeJ"
      },
      "outputs": [],
      "source": [
        "def data_visualization(input_data):\n",
        "    \"\"\"\n",
        "    This function visualize input data so it could be analysed.\n",
        "\n",
        "    :param input_data: dataframe which contains data to be visualized\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    my_colors = ['black', 'red', 'green', 'blue', 'cyan', 'silver', 'gold', 'slategrey', 'crimson', 'olive', 'orange',\n",
        "                 'tomato', 'navy', 'lime', 'violet']\n",
        "\n",
        "    input_data['dx'].value_counts().plot(kind='bar', color=my_colors)\n",
        "\n",
        "    x = ['Melanocytic nevi', 'Melanoma', 'Benign keratosis-like lesions', 'Basal cell carcinoma', 'Actinic keratoses',\n",
        "         'Vascular lesions', 'Dermatofibroma']\n",
        "    values = np.arange(0, 7, 1)\n",
        "\n",
        "    plt.xticks(values, x,\n",
        "               rotation=90)\n",
        "    plt.title(\"Diseases\")\n",
        "    plt.xlabel(\"Diseases type\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/diseases_type_graph.png',\n",
        "                bbox_inches='tight')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    input_data['dx_type'].value_counts().plot(kind='bar',\n",
        "                                              color=my_colors)\n",
        "\n",
        "    plt.title(\"Technical validation\")\n",
        "    plt.xlabel(\"Technical validation type\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/technical_validation_graph.png',\n",
        "                bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    input_data['age'].hist(color='darkred',\n",
        "                           histtype='bar',\n",
        "                           ec='black')\n",
        "\n",
        "    plt.title(\"Age\")\n",
        "    plt.xlabel(\"Age\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.margins(x=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/age_graph.png',\n",
        "                bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    input_data['sex'].value_counts().plot(kind='pie')\n",
        "    plt.title(\"Sex\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/sex_graph.png',\n",
        "                bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    input_data['localization'].value_counts().plot(kind='bar',\n",
        "                                                   color=my_colors)\n",
        "\n",
        "    plt.title(\"Localization\")\n",
        "    plt.xlabel(\"Localization place\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/localization_graph.png',\n",
        "                bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Diseases depending on age\")\n",
        "    plt.xlabel(\"Disease\")\n",
        "    plt.ylabel(\"Age\")\n",
        "    plt.xticks(values, x,\n",
        "               rotation=90)\n",
        "\n",
        "    plt.scatter(input_data['dx'], input_data['age'],\n",
        "                color=\"red\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/diseases_depending_on_age.png',\n",
        "                bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Diseases depending on localization\")\n",
        "    plt.xlabel(\"Disease\")\n",
        "    plt.ylabel(\"Sex\")\n",
        "    plt.xticks(values, x,\n",
        "               rotation=90)\n",
        "\n",
        "    plt.scatter(input_data['dx'], input_data['sex'],\n",
        "                color=\"blue\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/diseases_depending_on_sex.png',\n",
        "                bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Diseases depending on localization\")\n",
        "    plt.xlabel(\"Disease\")\n",
        "    plt.ylabel(\"Localization\")\n",
        "    plt.xticks(values, x,\n",
        "               rotation=90)\n",
        "\n",
        "    plt.scatter(input_data['dx'], input_data['localization'],\n",
        "                color=\"green\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/diseases_depending_on_localization.png',\n",
        "                bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Localization depending on sex\")\n",
        "    plt.xlabel(\"Localization\")\n",
        "    plt.ylabel(\"Sex\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.scatter(input_data['localization'], input_data['sex'],\n",
        "                color=\"gray\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data_analysis/input_data_analysis_results/localization_depending_on_sex.png',\n",
        "                bbox_inches='tight')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDF4RxUfB3iD"
      },
      "outputs": [],
      "source": [
        "data_visualization(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcH2w2brD7p_"
      },
      "source": [
        "**Data engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOM9AhjyEART"
      },
      "outputs": [],
      "source": [
        "def drop_unknown_sex_localization(input_data):\n",
        "    \"\"\"\n",
        "    This function drops data which has unknown sex or localization cell.\n",
        "\n",
        "    :param input_data: dataframe to be processed\n",
        "    :return: input_data - input dataframe with dropped unknown sex or localization cell\n",
        "    \"\"\"\n",
        "\n",
        "    ids_unknown_sex = pd.unique(input_data[input_data['sex'] == 'unknown']['image_id'])\n",
        "    ids_unknown_localization = pd.unique(input_data[input_data['localization'] == 'unknown']['image_id'])\n",
        "    ids_unknown = np.unique(np.append(ids_unknown_sex, ids_unknown_localization))\n",
        "\n",
        "    input_data.drop(index=input_data.loc[input_data['image_id'].isin(ids_unknown)].index,\n",
        "                    axis=0,\n",
        "                    inplace=True)\n",
        "\n",
        "    input_data = input_data.reset_index(drop=True)\n",
        "\n",
        "    return input_data\n",
        "\n",
        "\n",
        "def drop_missing_data(dropped_unknown_sex_localization):\n",
        "    \"\"\"\n",
        "    This function drops data which has any null cells.\n",
        "\n",
        "    :param dropped_unknown_sex_localization: dataframe to be processed\n",
        "    :return: dropped_unknown_sex_localization - input dataframe with dropped null cells\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Number of data which has nulls: {dropped_unknown_sex_localization['age'].isna().sum()}\")\n",
        "    dropped_unknown_sex_localization.drop(\n",
        "        index=dropped_unknown_sex_localization.loc[dropped_unknown_sex_localization['age'].isna()].index,\n",
        "        axis=0,\n",
        "        inplace=True)\n",
        "\n",
        "    dropped_unknown_sex_localization = dropped_unknown_sex_localization.reset_index(drop=True)\n",
        "\n",
        "    return dropped_unknown_sex_localization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--fUFA49EIL3"
      },
      "outputs": [],
      "source": [
        "dropped_unknown_sex_localization = drop_unknown_sex_localization(input_data)\n",
        "\n",
        "dropped_missing_data = drop_missing_data(dropped_unknown_sex_localization)\n",
        "\n",
        "dropped_missing_data.to_csv(\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/preprocessing/dropped_unknown_sex_localization_nulls.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DPbY7U1Ebpb"
      },
      "outputs": [],
      "source": [
        "dropped_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhhmwWnmEeTQ"
      },
      "outputs": [],
      "source": [
        "dropped_unknown_sex_localization_nulls = pd.read_csv(\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/preprocessing/dropped_unknown_sex_localization_nulls.csv\",\n",
        "                             header=0,\n",
        "                             index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaazORUFE4Zh"
      },
      "outputs": [],
      "source": [
        "dropped_unknown_sex_localization_nulls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkEkuUiMFQd_"
      },
      "outputs": [],
      "source": [
        "def add_images_path(input_data):\n",
        "    \"\"\"\n",
        "    This function adds new column with image paths for each data.\n",
        "\n",
        "    :param input_data: dataframe to be processed\n",
        "    :return: input_data - dataframe with ned column with image path\n",
        "    \"\"\"\n",
        "\n",
        "    image_part_1_path = '/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/input/HAM10000_images_part_1/'\n",
        "    image_part_2_path = '/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/input/HAM10000_images_part_2/'\n",
        "    extension = '.jpg'\n",
        "\n",
        "    input_data['image_path'] = input_data.apply(lambda x: np.where(\n",
        "        os.path.exists(str(image_part_1_path + x['image_id'] + extension)),\n",
        "        str(image_part_1_path + x['image_id'] + extension),\n",
        "        str(image_part_2_path + x['image_id'] + extension)),\n",
        "                                                axis=1)\n",
        "\n",
        "    file_path = str(input_data.loc[0]['image_path'])\n",
        "    plt.title(\"Disease Image\")\n",
        "    plt.xlabel(\"X pixel scaling\")\n",
        "    plt.ylabel(\"Y pixels scaling\")\n",
        "\n",
        "    image = mpimg.imread(file_path)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "    return input_data\n",
        "\n",
        "\n",
        "def add_disease_classes(added_images):\n",
        "    \"\"\"\n",
        "    This function adds new column which contains codes of each disease.\n",
        "\n",
        "    :param added_images: input dataframe to be processed\n",
        "    :return: added_images - dataframe with new column with diseases codes\n",
        "    \"\"\"\n",
        "\n",
        "    diseases_dict = {\n",
        "        'nv': 'Melanocytic nevi',\n",
        "        'mel': 'Melanoma',\n",
        "        'bkl': 'Benign keratosis-like lesions',\n",
        "        'bcc': 'Basal cell carcinoma',\n",
        "        'akiec': 'Actinic keratoses',\n",
        "        'vasc': 'Vascular lesions',\n",
        "        'df': 'Dermatofibroma'\n",
        "    }\n",
        "\n",
        "    added_images['diseases'] = added_images.apply(lambda x: diseases_dict[x['dx']],\n",
        "                                                  axis=1)\n",
        "\n",
        "    added_images['diseases_code'] = pd.Categorical(added_images['diseases']).codes\n",
        "\n",
        "    return added_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZJlnas1E5-V"
      },
      "outputs": [],
      "source": [
        "added_images_path = add_images_path(dropped_unknown_sex_localization_nulls)\n",
        "added_images_diseases_classes = add_disease_classes(added_images_path)\n",
        "\n",
        "added_images_diseases_classes.to_csv(\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/preprocessing/added_images_diseases_classes.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r5bDf1IFw-3"
      },
      "outputs": [],
      "source": [
        "added_images_diseases_classes = pd.read_csv(\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/preprocessing/added_images_diseases_classes.csv\",\n",
        "                             header=0,\n",
        "                             index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PxRj6L8GIRt"
      },
      "outputs": [],
      "source": [
        "added_images_diseases_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DBhxRQ5Gc1g"
      },
      "outputs": [],
      "source": [
        "def create_dummies_categorical_columns(input_data):\n",
        "    \"\"\"\n",
        "    This function creates dummy columns from categorical column, exactly \"dx_type\" and \"localization\" columns.\n",
        "\n",
        "    :param input_data: dataframe to be processed\n",
        "    :return: input_data - dataframe with dummy columns\n",
        "    \"\"\"\n",
        "\n",
        "    input_data = pd.get_dummies(input_data,\n",
        "                                columns=[\"dx_type\", \"localization\"])\n",
        "\n",
        "    return input_data\n",
        "\n",
        "\n",
        "def label_encoding_sex_column(df_with_dummies):\n",
        "    \"\"\"\n",
        "    This function converts categorical sex column to numerical one.\n",
        "\n",
        "    :param df_with_dummies: dataframe to be processed\n",
        "    :return: df_with_dummies - dataframe with converted column\n",
        "    \"\"\"\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    df_with_dummies['sex'] = le.fit_transform(df_with_dummies['sex'])\n",
        "\n",
        "    return df_with_dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbXsuAWkGJDQ"
      },
      "outputs": [],
      "source": [
        "df_with_dummies = create_dummies_categorical_columns(added_images_diseases_classes)\n",
        "\n",
        "converted_categorical_columns = label_encoding_sex_column(df_with_dummies)\n",
        "\n",
        "converted_categorical_columns.to_csv(\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/preprocessing/converted_categorical_columns.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw-FphfMHiIX"
      },
      "source": [
        "**Machine Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bYQ1Rf_IQKf"
      },
      "outputs": [],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqxfHqb_OUhm"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from itertools import cycle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiZ-uChaOoRo"
      },
      "outputs": [],
      "source": [
        "converted_categorical_columns = pd.read_csv(\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/preprocessing/converted_categorical_columns.csv\",\n",
        "                             header=0,\n",
        "                             index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSKIS_rpOvIa"
      },
      "outputs": [],
      "source": [
        "converted_categorical_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocNF4Vj2OaVX"
      },
      "outputs": [],
      "source": [
        "def split_with_stratify(input_data):\n",
        "    label = input_data['diseases_code']\n",
        "    features = input_data.drop(columns='diseases_code')\n",
        "\n",
        "    print(\"Input data:\")\n",
        "    print(input_data['diseases'].value_counts(normalize=True) * 100)\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features,\n",
        "                                                        label,\n",
        "                                                        test_size=0.2,\n",
        "                                                        stratify=features['diseases'],\n",
        "                                                        random_state=0)\n",
        "\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
        "                                                      y_train,\n",
        "                                                      test_size=0.25,\n",
        "                                                      stratify=x_train['diseases'],\n",
        "                                                      random_state=0)\n",
        "    print(\"X train data:\")\n",
        "    print(x_train['diseases'].value_counts(normalize=True) * 100)\n",
        "    print(len(x_train))\n",
        "\n",
        "    print(\"X validation data:\")\n",
        "    print(x_val['diseases'].value_counts(normalize=True) * 100)\n",
        "    print(len(x_val))\n",
        "\n",
        "    print(\"X test data:\")\n",
        "    print(x_test['diseases'].value_counts(normalize=True) * 100)\n",
        "    print(len(x_test))\n",
        "\n",
        "    return x_train, x_test, x_val, y_val, y_train, y_test\n",
        "\n",
        "\n",
        "def move_images_to_directories(x_train, x_test, x_val):\n",
        "    train_directory = '/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/train/'\n",
        "    test_directory = '/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/test/'\n",
        "    val_directory = '/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/validation/'\n",
        "\n",
        "    base_path = \"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/\"\n",
        "    train_path = base_path + \"train/\"\n",
        "    test_path = base_path + \"test/\"\n",
        "    val_path = base_path + \"validation/\"\n",
        "    base_path_extended = [train_path, test_path, val_path]\n",
        "    dx_list = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "\n",
        "    directory_list = []\n",
        "    for path in base_path_extended:\n",
        "        paths_to_be_added = list(map(str.__add__, cycle([path]), dx_list))\n",
        "        directory_list.extend(paths_to_be_added)\n",
        "\n",
        "    if os.path.exists(directory_list[0]):\n",
        "        print(\"Data already split, exiting\")\n",
        "        exit(0)\n",
        "\n",
        "    for directory in directory_list:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    x_train.apply(lambda x: shutil.copy(x['image_path'], train_directory + x['dx'] + '/'),\n",
        "                  axis=1)\n",
        "    x_test.apply(lambda x: shutil.copy(x['image_path'], test_directory + x['dx'] + '/'),\n",
        "                 axis=1)\n",
        "    x_val.apply(lambda x: shutil.copy(x['image_path'], val_directory + x['dx'] + '/'),\n",
        "                axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1vcHQW7O6oC"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, x_val, y_val, y_train, y_test = split_with_stratify(converted_categorical_columns)\n",
        "\n",
        "x_train.to_csv('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/x_train.csv', index=0)\n",
        "x_test.to_csv('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/x_test.csv', index=0)\n",
        "x_val.to_csv('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/x_val.csv', index=0)\n",
        "y_train.to_csv('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/y_train.csv', index=0)\n",
        "y_test.to_csv('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/y_test.csv', index=0)\n",
        "y_val.to_csv('/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/y_val.csv', index=0)\n",
        "\n",
        "move_images_to_directories(x_train, x_test, x_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LntNg39BIZ0f"
      },
      "source": [
        "***Experiments:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwR-kHkPHs2S"
      },
      "source": [
        "1. **Alex Net**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nwkGv_PIbY3"
      },
      "outputs": [],
      "source": [
        "def AlexNetExp(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(filters=96,\n",
        "                            kernel_size=(11, 11),\n",
        "                            strides=(4, 4),\n",
        "                            activation=\"relu\",\n",
        "                            input_shape=(227, 227, 3)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPool2D(pool_size=(3, 3),\n",
        "                               strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=256,\n",
        "                            kernel_size=(5, 5),\n",
        "                            strides=(1, 1),\n",
        "                            activation=\"relu\",\n",
        "                            padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPool2D(pool_size=(3, 3),\n",
        "                               strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=384,\n",
        "                            kernel_size=(3, 3),\n",
        "                            strides=(1, 1),\n",
        "                            activation=\"relu\",\n",
        "                            padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=384,\n",
        "                            kernel_size=(3, 3),\n",
        "                            strides=(1, 1),\n",
        "                            activation=\"relu\",\n",
        "                            padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=256,\n",
        "                            kernel_size=(3, 3),\n",
        "                            strides=(1, 1),\n",
        "                            activation=\"relu\",\n",
        "                            padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPool2D(pool_size=(3, 3),\n",
        "                               strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(4096, activation=\"relu\"))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(4096, activation=\"relu\"))\n",
        "\n",
        "    model.add(layers.Dense(7, activation=\"softmax\"))\n",
        "\n",
        "    hp_learning_rate = hp.Float(\"learning_rate\",\n",
        "                                 min_value=1e-6,\n",
        "                                 max_value=1e-1,\n",
        "                                 step=10,\n",
        "                                 sampling=\"log\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2yJZkKqNA1d"
      },
      "source": [
        "2. **Google Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldacz5FMMA1Q"
      },
      "outputs": [],
      "source": [
        "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4):\n",
        "    # Input:\n",
        "    # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
        "    # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
        "    # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
        "    # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
        "\n",
        "    # 1st path:\n",
        "    path1 = layers.Conv2D(filters=f1,\n",
        "                          kernel_size=(1, 1),\n",
        "                          padding='same',\n",
        "                          activation='relu')(input_layer)\n",
        "\n",
        "    # 2nd path\n",
        "    path2 = layers.Conv2D(filters=f2_conv1,\n",
        "                          kernel_size=(1, 1),\n",
        "                          padding='same',\n",
        "                          activation='relu')(input_layer)\n",
        "    path2 = layers.Conv2D(filters=f2_conv3,\n",
        "                          kernel_size=(3, 3),\n",
        "                          padding='same',\n",
        "                          activation='relu')(path2)\n",
        "\n",
        "    # 3rd path\n",
        "    path3 = layers.Conv2D(filters=f3_conv1,\n",
        "                          kernel_size=(1, 1),\n",
        "                          padding='same',\n",
        "                          activation='relu')(input_layer)\n",
        "    path3 = layers.Conv2D(filters=f3_conv5,\n",
        "                          kernel_size=(5, 5),\n",
        "                          padding='same',\n",
        "                          activation='relu')(path3)\n",
        "\n",
        "    # 4th path\n",
        "    path4 = layers.MaxPooling2D((3, 3),\n",
        "                                strides=(1, 1),\n",
        "                                padding='same')(input_layer)\n",
        "    path4 = layers.Conv2D(filters=f4,\n",
        "                          kernel_size=(1, 1),\n",
        "                          padding='same',\n",
        "                          activation='relu')(path4)\n",
        "\n",
        "    output_layer = layers.concatenate([path1, path2, path3, path4],\n",
        "                                      axis=-1)\n",
        "\n",
        "    return output_layer\n",
        "\n",
        "\n",
        "def GoogleNetExp(hp):\n",
        "    # input layer\n",
        "    input_layer = layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
        "    X = layers.Conv2D(filters=64,\n",
        "                      kernel_size=(7, 7),\n",
        "                      strides=2,\n",
        "                      padding='valid',\n",
        "                      activation='relu')(input_layer)\n",
        "\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(X)\n",
        "\n",
        "    # convolutional layer: filters = 64, strides = 1\n",
        "    X = layers.Conv2D(filters=64,\n",
        "                      kernel_size=(1, 1),\n",
        "                      strides=1,\n",
        "                      padding='same',\n",
        "                      activation='relu')(X)\n",
        "\n",
        "    # convolutional layer: filters = 192, kernel_size = (3,3)\n",
        "    X = layers.Conv2D(filters=192,\n",
        "                      kernel_size=(3, 3),\n",
        "                      padding='same',\n",
        "                      activation='relu')(X)\n",
        "\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(X)\n",
        "\n",
        "    # 1st Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=64,\n",
        "                        f2_conv1=96,\n",
        "                        f2_conv3=128,\n",
        "                        f3_conv1=16,\n",
        "                        f3_conv5=32,\n",
        "                        f4=32)\n",
        "\n",
        "    # 2nd Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=128,\n",
        "                        f2_conv1=128,\n",
        "                        f2_conv3=192,\n",
        "                        f3_conv1=32,\n",
        "                        f3_conv5=96,\n",
        "                        f4=64)\n",
        "\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(X)\n",
        "\n",
        "    # 3rd Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=192,\n",
        "                        f2_conv1=96,\n",
        "                        f2_conv3=208,\n",
        "                        f3_conv1=16,\n",
        "                        f3_conv5=48,\n",
        "                        f4=64)\n",
        "\n",
        "    # Extra network 1:\n",
        "    X1 = layers.AveragePooling2D(pool_size=(5, 5),\n",
        "                                 strides=3)(X)\n",
        "    X1 = layers.Conv2D(filters=128,\n",
        "                       kernel_size=(1, 1),\n",
        "                       padding='same',\n",
        "                       activation='relu')(X1)\n",
        "    X1 = layers.Flatten()(X1)\n",
        "    X1 = layers.Dense(1024,\n",
        "                      activation='relu')(X1)\n",
        "    X1 = layers.Dropout(0.7)(X1)\n",
        "    X1 = layers.Dense(7,\n",
        "                      activation='softmax')(X1)\n",
        "\n",
        "    # 4th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=160,\n",
        "                        f2_conv1=112,\n",
        "                        f2_conv3=224,\n",
        "                        f3_conv1=24,\n",
        "                        f3_conv5=64,\n",
        "                        f4=64)\n",
        "\n",
        "    # 5th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=128,\n",
        "                        f2_conv1=128,\n",
        "                        f2_conv3=256,\n",
        "                        f3_conv1=24,\n",
        "                        f3_conv5=64,\n",
        "                        f4=64)\n",
        "\n",
        "    # 6th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=112,\n",
        "                        f2_conv1=144,\n",
        "                        f2_conv3=288,\n",
        "                        f3_conv1=32,\n",
        "                        f3_conv5=64,\n",
        "                        f4=64)\n",
        "\n",
        "    # Extra network 2:\n",
        "    X2 = layers.AveragePooling2D(pool_size=(5, 5),\n",
        "                                 strides=3)(X)\n",
        "    X2 = layers.Conv2D(filters=128,\n",
        "                       kernel_size=(1, 1),\n",
        "                       padding='same',\n",
        "                       activation='relu')(X2)\n",
        "    X2 = layers.Flatten()(X2)\n",
        "    X2 = layers.Dense(1024,\n",
        "                      activation='relu')(X2)\n",
        "    X2 = layers.Dropout(0.7)(X2)\n",
        "    X2 = layers.Dense(7,\n",
        "                      activation='softmax')(X2)\n",
        "\n",
        "    # 7th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=256,\n",
        "                        f2_conv1=160,\n",
        "                        f2_conv3=320,\n",
        "                        f3_conv1=32,\n",
        "                        f3_conv5=128,\n",
        "                        f4=128)\n",
        "\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(X)\n",
        "\n",
        "    # 8th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=256,\n",
        "                        f2_conv1=160,\n",
        "                        f2_conv3=320,\n",
        "                        f3_conv1=32,\n",
        "                        f3_conv5=128,\n",
        "                        f4=128)\n",
        "\n",
        "    # 9th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=384,\n",
        "                        f2_conv1=192,\n",
        "                        f2_conv3=384,\n",
        "                        f3_conv1=48,\n",
        "                        f3_conv5=128,\n",
        "                        f4=128)\n",
        "\n",
        "    # Global Average pooling layer\n",
        "    X = layers.GlobalAveragePooling2D(name='GAPL')(X)\n",
        "\n",
        "    # Dropout layer\n",
        "    X = layers.Dropout(0.4)(X)\n",
        "\n",
        "    # output layer\n",
        "    X = layers.Dense(7,\n",
        "                     activation='softmax')(X)\n",
        "\n",
        "    # model\n",
        "    model = Model(input_layer, [X, X1, X2],\n",
        "                  name='GoogLeNet')\n",
        "\n",
        "    hp_learning_rate = hp.Float(\"learning_rate\",\n",
        "                                 min_value=1e-6,\n",
        "                                 max_value=1e-1,\n",
        "                                 step=10,\n",
        "                                 sampling=\"log\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ltb5dPsNFUj"
      },
      "source": [
        "3. **Le Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4idQI6hMHQA"
      },
      "outputs": [],
      "source": [
        "def LeNetExp(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='tanh', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.AveragePooling2D())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='tanh'))\n",
        "    model.add(layers.AveragePooling2D())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=120, kernel_size=(5, 5), activation='tanh'))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=84, activation='tanh'))\n",
        "    model.add(layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "    hp_learning_rate = hp.Float(\"learning_rate\",\n",
        "                                 min_value=1e-6,\n",
        "                                 max_value=1e-1,\n",
        "                                 step=10,\n",
        "                                 sampling=\"log\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQZtDPwyNVyW"
      },
      "source": [
        "4. **Res Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TCzYo9BMHbc"
      },
      "outputs": [],
      "source": [
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = layers.ReLU()(inputs)\n",
        "    bn = layers.BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = layers.Conv2D(kernel_size=kernel_size,\n",
        "                      strides=(1 if not downsample else 2),\n",
        "                      filters=filters,\n",
        "                      padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = layers.Conv2D(kernel_size=kernel_size,\n",
        "                      strides=1,\n",
        "                      filters=filters,\n",
        "                      padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = layers.Conv2D(kernel_size=1,\n",
        "                          strides=2,\n",
        "                          filters=filters,\n",
        "                          padding=\"same\")(x)\n",
        "    out = layers.Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "def ResNetExp(hp):\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "    num_filters = 64\n",
        "\n",
        "    t = layers.BatchNormalization()(inputs)\n",
        "    t = layers.Conv2D(kernel_size=3,\n",
        "                      strides=1,\n",
        "                      filters=num_filters,\n",
        "                      padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "\n",
        "    num_blocks_list = [2, 5, 5, 2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j == 0 and i != 0), filters=num_filters)\n",
        "        num_filters *= 2\n",
        "\n",
        "    t = layers.AveragePooling2D(4)(t)\n",
        "    t = layers.Flatten()(t)\n",
        "    outputs = layers.Dense(7, activation='softmax')(t)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    hp_learning_rate = hp.Float(\"learning_rate\",\n",
        "                                 min_value=1e-6,\n",
        "                                 max_value=1e-1,\n",
        "                                 step=10,\n",
        "                                 sampling=\"log\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pRd8khrNYgM"
      },
      "source": [
        "5. **VGG Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eSifUqXMHj5"
      },
      "outputs": [],
      "source": [
        "def VGGNetExp(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(\n",
        "        layers.Conv2D(input_shape=(224, 224, 3), filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=4096, activation=\"relu\"))\n",
        "    model.add(layers.Dense(units=4096, activation=\"relu\"))\n",
        "    model.add(layers.Dense(units=7, activation=\"softmax\"))\n",
        "\n",
        "    hp_learning_rate = hp.Float(\"learning_rate\",\n",
        "                                 min_value=1e-6,\n",
        "                                 max_value=1e-1,\n",
        "                                 step=10,\n",
        "                                 sampling=\"log\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYUZ854UIgZZ"
      },
      "outputs": [],
      "source": [
        "def train_model_experiment(model):\n",
        "    dimensions = (0, 0)\n",
        "    directory_name = \"\"\n",
        "    model_to_train = None\n",
        "\n",
        "    match model:\n",
        "      case \"AlexNet\":\n",
        "        dimensions = (227, 227)\n",
        "        directory_name = \"AlexNet\"\n",
        "        model_to_train = AlexNetExp\n",
        "      case \"LeNet\":\n",
        "        dimensions = (32, 32)\n",
        "        directory_name = \"LeNet\"\n",
        "        model_to_train = LeNetExp\n",
        "      case \"GoogleNet\":\n",
        "        dimensions = (224, 224)\n",
        "        directory_name = \"GoogleNet\"\n",
        "        model_to_train = GoogleNetExp\n",
        "      case \"ResNet\":\n",
        "        dimensions = (32, 32)\n",
        "        directory_name = \"ResNet\"\n",
        "        model_to_train = ResNetExp\n",
        "      case \"VGGNet\":\n",
        "        dimensions = (224, 224)\n",
        "        directory_name = \"VGGNet\"\n",
        "        model_to_train = VGGNetExp\n",
        "      case _:\n",
        "        dimensions = (-1, -1)\n",
        "        directory_name = \"Wrong input given\"\n",
        "        exit(-1)\n",
        "\n",
        "    train_dir = \"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/train//\"\n",
        "    validation_dir = \"/content/drive/MyDrive/skin_diseases_recognition_using_ml/data/final_data_for_training_model/validation//\"\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=dimensions,\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\"\n",
        "    )\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=dimensions,\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\"\n",
        "    )\n",
        "\n",
        "    train_img, train_labels = train_generator.next()\n",
        "    validation_img, validation_labels = validation_generator.next()\n",
        "\n",
        "    tuner = RandomSearch(\n",
        "        model_to_train,\n",
        "        objective='val_accuracy',\n",
        "        max_trials=6,\n",
        "        executions_per_trial=5,\n",
        "        overwrite=True,\n",
        "        directory=directory_name+ '_experiments',\n",
        "        project_name='skin_patterns_recognition_using_ML'\n",
        "    )\n",
        "\n",
        "    tuner.search_space_summary()\n",
        "\n",
        "    tuner.search(train_img, train_labels,\n",
        "                 epochs=10,\n",
        "                 validation_data=(validation_img, validation_labels),\n",
        "                 batch_size=32)\n",
        "\n",
        "    tuner.results_summary()\n",
        "\n",
        "    best_model = tuner.get_best_models()[0]\n",
        "\n",
        "    print(f\"Best model: {best_model}\")\n",
        "\n",
        "    best_hp = tuner.get_best_hyperparameters()[0].values\n",
        "\n",
        "    print(f\"Best hyperpameters: {best_hp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuYS6xslJqRx"
      },
      "outputs": [],
      "source": [
        "train_model_experiment(\"AlexNet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OywfkxJg0WAd"
      },
      "outputs": [],
      "source": [
        "train_model_experiment(\"LeNet\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_experiment(\"GoogleNet\")"
      ],
      "metadata": {
        "id": "diUoTEqmQdbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_experiment(\"VGGNet\")"
      ],
      "metadata": {
        "id": "aqqOlIh8RvN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_experiment(\"ResNet\")"
      ],
      "metadata": {
        "id": "AsiYJxuOSBu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kFgNOiUcSSOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Models implementation:***"
      ],
      "metadata": {
        "id": "_HpWFuC4SxnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Alex Net**"
      ],
      "metadata": {
        "id": "ZpVsSzFXS4ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AlexNet():\n",
        "    with strategy.scope():\n",
        "      model = Sequential()\n",
        "\n",
        "      model.add(layers.Conv2D(filters=96,\n",
        "                              kernel_size=(11, 11),\n",
        "                              strides=(4, 4),\n",
        "                              activation=\"relu\",\n",
        "                              input_shape=(227, 227, 3)))\n",
        "      model.add(layers.BatchNormalization())\n",
        "      model.add(layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=(2, 2)))\n",
        "\n",
        "      model.add(layers.Conv2D(filters=256,\n",
        "                              kernel_size=(5, 5),\n",
        "                              strides=(1, 1),\n",
        "                              activation=\"relu\",\n",
        "                              padding=\"same\"))\n",
        "      model.add(layers.BatchNormalization())\n",
        "      model.add(layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=(2, 2)))\n",
        "\n",
        "      model.add(layers.Conv2D(filters=384,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=(1, 1),\n",
        "                              activation=\"relu\",\n",
        "                              padding=\"same\"))\n",
        "      model.add(layers.BatchNormalization())\n",
        "\n",
        "      model.add(layers.Conv2D(filters=384,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=(1, 1),\n",
        "                              activation=\"relu\",\n",
        "                              padding=\"same\"))\n",
        "      model.add(layers.BatchNormalization())\n",
        "\n",
        "      model.add(layers.Conv2D(filters=256,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=(1, 1),\n",
        "                              activation=\"relu\",\n",
        "                              padding=\"same\"))\n",
        "      model.add(layers.BatchNormalization())\n",
        "      model.add(layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=(2, 2)))\n",
        "\n",
        "      model.add(layers.Flatten())\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Dense(4096, activation=\"relu\"))\n",
        "      model.add(layers.Dropout(0.5))\n",
        "      model.add(layers.Dense(4096, activation=\"relu\"))\n",
        "\n",
        "      model.add(layers.Dense(7, activation=\"softmax\"))\n",
        "\n",
        "      return model"
      ],
      "metadata": {
        "id": "1kqNHZXwS0ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Google Net**"
      ],
      "metadata": {
        "id": "XagWo5k_TErZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4):\n",
        "    # Input:\n",
        "    # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
        "    # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
        "    # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
        "    # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
        "\n",
        "    # 1st path:\n",
        "    path1 = layers.Conv2D(filters=f1,\n",
        "                          kernel_size=(1, 1),\n",
        "                          padding='same',\n",
        "                          activation='relu')(input_layer)\n",
        "\n",
        "    # 2nd path\n",
        "    path2 = layers.Conv2D(filters=f2_conv1,\n",
        "                          kernel_size=(1, 1),\n",
        "                          padding='same',\n",
        "                          activation='relu')(input_layer)\n",
        "    path2 = layers.Conv2D(filters=f2_conv3,\n",
        "                          kernel_size=(3, 3),\n",
        "                          padding='same',\n",
        "                          activation='relu')(path2)\n",
        "\n",
        "    # 3rd path\n",
        "    path3 = layers.Conv2D(filters=f3_conv1,\n",
        "                          kernel_size=(1, 1),\n",
        "                          padding='same',\n",
        "                          activation='relu')(input_layer)\n",
        "    path3 = layers.Conv2D(filters=f3_conv5,\n",
        "                          kernel_size=(5, 5),\n",
        "                          padding='same',\n",
        "                          activation='relu')(path3)\n",
        "\n",
        "    # 4th path\n",
        "    path4 = layers.MaxPooling2D((3, 3),\n",
        "                                strides=(1, 1),\n",
        "                                padding='same')(input_layer)\n",
        "    path4 = layers.Conv2D(filters=f4,\n",
        "                          kernel_size=(1, 1),\n",
        "                          padding='same',\n",
        "                          activation='relu')(path4)\n",
        "\n",
        "    output_layer = layers.concatenate([path1, path2, path3, path4],\n",
        "                                      axis=-1)\n",
        "\n",
        "    return output_layer\n",
        "\n",
        "\n",
        "def GoogleNet():\n",
        "  with strategy.scope():\n",
        "    # input layer\n",
        "    input_layer = layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
        "    X = layers.Conv2D(filters=64,\n",
        "                      kernel_size=(7, 7),\n",
        "                      strides=2,\n",
        "                      padding='valid',\n",
        "                      activation='relu')(input_layer)\n",
        "\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(X)\n",
        "\n",
        "    # convolutional layer: filters = 64, strides = 1\n",
        "    X = layers.Conv2D(filters=64,\n",
        "                      kernel_size=(1, 1),\n",
        "                      strides=1,\n",
        "                      padding='same',\n",
        "                      activation='relu')(X)\n",
        "\n",
        "    # convolutional layer: filters = 192, kernel_size = (3,3)\n",
        "    X = layers.Conv2D(filters=192,\n",
        "                      kernel_size=(3, 3),\n",
        "                      padding='same',\n",
        "                      activation='relu')(X)\n",
        "\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(X)\n",
        "\n",
        "    # 1st Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=64,\n",
        "                        f2_conv1=96,\n",
        "                        f2_conv3=128,\n",
        "                        f3_conv1=16,\n",
        "                        f3_conv5=32,\n",
        "                        f4=32)\n",
        "\n",
        "    # 2nd Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=128,\n",
        "                        f2_conv1=128,\n",
        "                        f2_conv3=192,\n",
        "                        f3_conv1=32,\n",
        "                        f3_conv5=96,\n",
        "                        f4=64)\n",
        "\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(X)\n",
        "\n",
        "    # 3rd Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=192,\n",
        "                        f2_conv1=96,\n",
        "                        f2_conv3=208,\n",
        "                        f3_conv1=16,\n",
        "                        f3_conv5=48,\n",
        "                        f4=64)\n",
        "\n",
        "    # Extra network 1:\n",
        "    X1 = layers.AveragePooling2D(pool_size=(5, 5),\n",
        "                                 strides=3)(X)\n",
        "    X1 = layers.Conv2D(filters=128,\n",
        "                       kernel_size=(1, 1),\n",
        "                       padding='same',\n",
        "                       activation='relu')(X1)\n",
        "    X1 = layers.Flatten()(X1)\n",
        "    X1 = layers.Dense(1024,\n",
        "                      activation='relu')(X1)\n",
        "    X1 = layers.Dropout(0.7)(X1)\n",
        "    X1 = layers.Dense(7,\n",
        "                      activation='softmax')(X1)\n",
        "\n",
        "    # 4th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=160,\n",
        "                        f2_conv1=112,\n",
        "                        f2_conv3=224,\n",
        "                        f3_conv1=24,\n",
        "                        f3_conv5=64,\n",
        "                        f4=64)\n",
        "\n",
        "    # 5th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=128,\n",
        "                        f2_conv1=128,\n",
        "                        f2_conv3=256,\n",
        "                        f3_conv1=24,\n",
        "                        f3_conv5=64,\n",
        "                        f4=64)\n",
        "\n",
        "    # 6th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=112,\n",
        "                        f2_conv1=144,\n",
        "                        f2_conv3=288,\n",
        "                        f3_conv1=32,\n",
        "                        f3_conv5=64,\n",
        "                        f4=64)\n",
        "\n",
        "    # Extra network 2:\n",
        "    X2 = layers.AveragePooling2D(pool_size=(5, 5),\n",
        "                                 strides=3)(X)\n",
        "    X2 = layers.Conv2D(filters=128,\n",
        "                       kernel_size=(1, 1),\n",
        "                       padding='same',\n",
        "                       activation='relu')(X2)\n",
        "    X2 = layers.Flatten()(X2)\n",
        "    X2 = layers.Dense(1024,\n",
        "                      activation='relu')(X2)\n",
        "    X2 = layers.Dropout(0.7)(X2)\n",
        "    X2 = layers.Dense(7,\n",
        "                      activation='softmax')(X2)\n",
        "\n",
        "    # 7th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=256,\n",
        "                        f2_conv1=160,\n",
        "                        f2_conv3=320,\n",
        "                        f3_conv1=32,\n",
        "                        f3_conv5=128,\n",
        "                        f4=128)\n",
        "\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(X)\n",
        "\n",
        "    # 8th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=256,\n",
        "                        f2_conv1=160,\n",
        "                        f2_conv3=320,\n",
        "                        f3_conv1=32,\n",
        "                        f3_conv5=128,\n",
        "                        f4=128)\n",
        "\n",
        "    # 9th Inception block\n",
        "    X = Inception_block(X,\n",
        "                        f1=384,\n",
        "                        f2_conv1=192,\n",
        "                        f2_conv3=384,\n",
        "                        f3_conv1=48,\n",
        "                        f3_conv5=128,\n",
        "                        f4=128)\n",
        "\n",
        "    # Global Average pooling layer\n",
        "    X = layers.GlobalAveragePooling2D(name='GAPL')(X)\n",
        "\n",
        "    # Dropout layer\n",
        "    X = layers.Dropout(0.4)(X)\n",
        "\n",
        "    # output layer\n",
        "    X = layers.Dense(7,\n",
        "                     activation='softmax')(X)\n",
        "\n",
        "    # model\n",
        "    model = Model(input_layer, [X, X1, X2],\n",
        "                  name='GoogLeNet')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "y2qKHGpOTEIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Le Net**"
      ],
      "metadata": {
        "id": "VaE-MGQFTTE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LeNet():\n",
        "  with strategy.scope():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='tanh', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.AveragePooling2D())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='tanh'))\n",
        "    model.add(layers.AveragePooling2D())\n",
        "\n",
        "    model.add(layers.Conv2D(filters=120, kernel_size=(5, 5), activation='tanh'))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=84, activation='tanh'))\n",
        "    model.add(layers.Dense(units=7, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "FYpW_to7TSN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Res Net**"
      ],
      "metadata": {
        "id": "3CCHmWU3Zci_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = layers.ReLU()(inputs)\n",
        "    bn = layers.BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = layers.Conv2D(kernel_size=kernel_size,\n",
        "                      strides=(1 if not downsample else 2),\n",
        "                      filters=filters,\n",
        "                      padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = layers.Conv2D(kernel_size=kernel_size,\n",
        "                      strides=1,\n",
        "                      filters=filters,\n",
        "                      padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = layers.Conv2D(kernel_size=1,\n",
        "                          strides=2,\n",
        "                          filters=filters,\n",
        "                          padding=\"same\")(x)\n",
        "    out = layers.Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "def ResNet():\n",
        "  with strategy.scope():\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "    num_filters = 64\n",
        "\n",
        "    t = layers.BatchNormalization()(inputs)\n",
        "    t = layers.Conv2D(kernel_size=3,\n",
        "                      strides=1,\n",
        "                      filters=num_filters,\n",
        "                      padding=\"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "\n",
        "    num_blocks_list = [2, 5, 5, 2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample=(j == 0 and i != 0), filters=num_filters)\n",
        "        num_filters *= 2\n",
        "\n",
        "    t = layers.AveragePooling2D(4)(t)\n",
        "    t = layers.Flatten()(t)\n",
        "    outputs = layers.Dense(7, activation='softmax')(t)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "n6iJ4-mUZbms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **VGG Net**"
      ],
      "metadata": {
        "id": "L5REMUCNZkTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VGGNet():\n",
        "  with strategy.scope():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(\n",
        "        layers.Conv2D(input_shape=(224, 224, 3), filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=4096, activation=\"relu\"))\n",
        "    model.add(layers.Dense(units=4096, activation=\"relu\"))\n",
        "    model.add(layers.Dense(units=7, activation=\"softmax\"))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "crpA9FmOZjpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, learning_rate, hardware_accelerator, batch_size):\n",
        "    dimensions = (0, 0)\n",
        "    directory_name = \"\"\n",
        "\n",
        "    match model:\n",
        "      case \"AlexNet\":\n",
        "        dimensions = (227, 227)\n",
        "        directory_name = \"AlexNet\"\n",
        "        model_to_train = AlexNet()\n",
        "      case \"LeNet\":\n",
        "        dimensions = (32, 32)\n",
        "        directory_name = \"LeNet\"\n",
        "        model_to_train = LeNet()\n",
        "      case \"GoogleNet\":\n",
        "        dimensions = (224, 224)\n",
        "        directory_name = \"GoogleNet\"\n",
        "        model_to_train = GoogleNet()\n",
        "      case \"ResNet\":\n",
        "        dimensions = (32, 32)\n",
        "        directory_name = \"ResNet\"\n",
        "        model_to_train = ResNet()\n",
        "      case \"VGGNet\":\n",
        "        dimensions = (224, 224)\n",
        "        directory_name = \"VGGNet\"\n",
        "        model_to_train = VGGNet()\n",
        "      case _:\n",
        "        dimensions = (-1, -1)\n",
        "        directory_name = \"Wrong input given\"\n",
        "        exit(-1)\n",
        "\n",
        "    train_dir = \"/content/skin_diseases_recognition_using_ml/data/final_data_for_training_model/train//\"\n",
        "    validation_dir = \"/content/skin_diseases_recognition_using_ml/data/final_data_for_training_model/validation//\"\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=dimensions,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"categorical\"\n",
        "    )\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=dimensions,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"categorical\"\n",
        "    )\n",
        "    # with tpu_strategy.scope():\n",
        "    #   model_to_train.compile(loss='categorical_crossentropy',\n",
        "    #                 optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
        "    #                 metrics=['accuracy'])\n",
        "    with tf.device('/TPU:0'):\n",
        "      model_to_train.compile(loss='categorical_crossentropy',\n",
        "                    optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "    model_to_train.summary()\n",
        "\n",
        "    history = model_to_train.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=50\n",
        "    )\n",
        "\n",
        "    plot_model(model_to_train, show_shapes=True)\n",
        "\n",
        "    model_to_train.save(f\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/final_results/saved_models/{directory_name}_model_lr_{learning_rate}_{batch_size}_{hardware_accelerator}_model.h5\")\n",
        "\n",
        "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "    plt.grid(True)\n",
        "    # plt.gca().set_ylim(0, 1)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/final_results/loss_functions/{directory_name}_model_lr_{learning_rate}_{batch_size}_{hardware_accelerator}_loss_function.png\",\n",
        "                bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jLJAariZZr1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "zzr760-XzHWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "train_model(\"AlexNet\", 0.001, \"TPU\", 16)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "fINT186bcdtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import models\n",
        "\n",
        "def prediction(model, learning_rate, hardware_accelerator, batch_size):\n",
        "    model = load_model(f\"/content/drive/MyDrive/skin_diseases_recognition_using_ml/final_results/saved_models/{model}_model_lr_{learning_rate}_{batch_size}_{hardware_accelerator}_model.h5\")\n",
        "\n",
        "    validation_dir = \"/content/skin_diseases_recognition_using_ml/data/final_data_for_training_model/validation//\"\n",
        "    test_dir = \"/content/skin_diseases_recognition_using_ml/data/final_data_for_training_model/test//\"\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # AlexNet - 227x227, LeNet - 32 x 32, GoogleNet - 224 x 224, ResNet - 32 x 32, VGGNet - 224 x 224\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(32, 32),\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle=False,\n",
        "        class_mode='categorical',\n",
        "        batch_size=1)\n",
        "\n",
        "    label_map = test_generator.class_indices\n",
        "\n",
        "    print(label_map)\n",
        "\n",
        "    filenames = test_generator.filenames\n",
        "    print(filenames[:100])\n",
        "    nb_samples = len(filenames)\n",
        "    print(nb_samples)\n",
        "\n",
        "    predict = model.predict(test_generator,\n",
        "                            steps=nb_samples)\n",
        "\n",
        "    scores = model.evaluate(test_generator)\n",
        "\n",
        "    print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")\n"
      ],
      "metadata": {
        "id": "Fz_da0v14M1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(\"AlexNet\", 0.00001, \"GPU\", 32)"
      ],
      "metadata": {
        "id": "7FEjJusvEeqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "n6vqnDdIjHHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "oWmx083rjFob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(file_path, dimensions):\n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.resize(img, dimensions)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "\n",
        "def load_dataset(dataset_path, dataset, model):\n",
        "    dimensions = (0, 0)\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    match model:\n",
        "      case \"AlexNet\":\n",
        "        dimensions = (227, 227)\n",
        "        directory_name = \"AlexNet\"\n",
        "      case \"LeNet\":\n",
        "        dimensions = (32, 32)\n",
        "        directory_name = \"LeNet\"\n",
        "      case \"GoogleNet\":\n",
        "        dimensions = (224, 224)\n",
        "        directory_name = \"GoogleNet\"\n",
        "      case \"ResNet\":\n",
        "        dimensions = (32, 32)\n",
        "        directory_name = \"ResNet\"\n",
        "      case \"VGGNet\":\n",
        "        dimensions = (224, 224)\n",
        "        directory_name = \"VGGNet\"\n",
        "      case _:\n",
        "        dimensions = (-1, -1)\n",
        "        directory_name = \"Wrong input given\"\n",
        "        exit(-1)\n",
        "\n",
        "    classes = sorted(os.listdir(dataset_path))\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            for file_name in os.listdir(class_path):\n",
        "                file_path = os.path.join(class_path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    img = preprocess_image(file_path, dimensions)\n",
        "                    images.append(img)\n",
        "                    labels.append(classes.index(class_name))\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "    # np.save(f'/content/skin_diseases_recognition_using_ml/data/saved_x_{dataset}_array', images)\n",
        "    # np.save(f'/content/skin_diseases_recognition_using_ml/data//saved_y_{dataset}_array', labels)\n"
      ],
      "metadata": {
        "id": "J6QrJU7hjZVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/skin_diseases_recognition_using_ml/data/final_data_for_training_model/'\n",
        "dataset_train = 'train'\n",
        "dataset_test = 'test'\n",
        "x_train_loaded = []\n",
        "y_train_loaded = []\n",
        "x_test_loaded = []\n",
        "y_test_loaded = []\n",
        "x_train, y_train = load_dataset(os.path.join(dataset_path, dataset_train), dataset_train, \"VGGNet\")\n",
        "x_test, y_test = load_dataset(os.path.join(dataset_path, dataset_test), dataset_test, \"VGGNet\")"
      ],
      "metadata": {
        "id": "85652gKWvjSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGGNet()"
      ],
      "metadata": {
        "id": "6wGypxn_kPAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "id": "OXL0U0xOjhKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.00001\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "pz1FYBH2GjXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4gcNVbAzkSuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=batch_size,\n",
        "          steps_per_epoch=100,\n",
        "          epochs=50,\n",
        "          validation_data=(x_test, y_test),\n",
        "          validation_steps=50)"
      ],
      "metadata": {
        "id": "zIetHnL8leUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If there is need to create TFRecord file (cases when dataset is too big):**"
      ],
      "metadata": {
        "id": "bZ398Bt0hm2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        processed_image = img.resize((desired_width, desired_height))\n",
        "        processed_image = processed_image.convert('RGB')\n",
        "        return processed_image.tobytes()\n",
        "\n",
        "def create_tfrecord(image_dir, output_dir, tfrecord_file):\n",
        "    writer = tf.io.TFRecordWriter(os.path.join(output_dir, tfrecord_file))\n",
        "\n",
        "    for root, _, files in os.walk(image_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.jpg'):\n",
        "                image_path = os.path.join(root, filename)\n",
        "                image_data = preprocess_image(image_path)\n",
        "\n",
        "                # Extract the class label from the parent folder name\n",
        "                class_label = os.path.basename(root)\n",
        "\n",
        "                feature = {\n",
        "                    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_data])),\n",
        "                    'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[class_label.encode()])),\n",
        "                }\n",
        "\n",
        "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "                serialized_example = example.SerializeToString()\n",
        "\n",
        "                writer.write(serialized_example)\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "# Set up directories and paths\n",
        "data_dir = '/content/skin_diseases_recognition_using_ml/data/final_data_for_training_model/'\n",
        "output_dir = '/content/skin_diseases_recognition_using_ml/data/tfrecords/'\n",
        "tfrecord_file = 'converted_images_to_tfrecords.tfrecord'\n",
        "\n",
        "# Set desired image size depending on needed architecture\n",
        "desired_width = 32\n",
        "desired_height = 32\n",
        "\n",
        "# Convert train folder to TFRecord\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "train_output_dir = os.path.join(output_dir, 'train')\n",
        "create_tfrecord(train_dir, train_output_dir, tfrecord_file)\n",
        "\n",
        "# Convert test folder to TFRecord\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "test_output_dir = os.path.join(output_dir, 'test')\n",
        "create_tfrecord(test_dir, test_output_dir, tfrecord_file)\n",
        "\n",
        "# Convert validation folder to TFRecord\n",
        "validation_dir = os.path.join(data_dir, 'validation')\n",
        "validation_output_dir = os.path.join(output_dir, 'validation')\n",
        "create_tfrecord(validation_dir, validation_output_dir, tfrecord_file)\n"
      ],
      "metadata": {
        "id": "KaveoPviWLfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_description = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.string),\n",
        "    'label': tf.io.FixedLenFeature([], tf.string),\n",
        "}"
      ],
      "metadata": {
        "id": "dNuPWKlvd1BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}  # Map string labels to integer labels\n",
        "\n",
        "def parse_tfrecord(example):\n",
        "    example = tf.io.parse_single_example(example, feature_description)\n",
        "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    return image, example['label']\n",
        "\n",
        "def convert_labels(image, label):\n",
        "    label = tf.numpy_function(lambda x: label_map[x.decode()], [label], tf.int32)\n",
        "    one_hot_label = tf.one_hot(label, depth=num_classes)\n",
        "    return image, one_hot_label"
      ],
      "metadata": {
        "id": "JVGeH791d39f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tfrecord_file = '/content/skin_diseases_recognition_using_ml/data/tfrecords/train/converted_images_to_tfrecords.tfrecord'\n",
        "test_tfrecord_file = '/content/skin_diseases_recognition_using_ml/data/tfrecords/test/converted_images_to_tfrecords.tfrecord'\n",
        "validation_tfrecord_file = '/content/skin_diseases_recognition_using_ml/data/tfrecords/validation/converted_images_to_tfrecords.tfrecord'\n",
        "\n",
        "train_dataset = tf.data.TFRecordDataset(train_tfrecord_file)\n",
        "test_dataset = tf.data.TFRecordDataset(test_tfrecord_file)\n",
        "validation_dataset = tf.data.TFRecordDataset(validation_tfrecord_file)\n",
        "\n",
        "parsed_train_dataset = train_dataset.map(parse_tfrecord)\n",
        "parsed_test_dataset = test_dataset.map(parse_tfrecord)\n",
        "parsed_validation_dataset = validation_dataset.map(parse_tfrecord)"
      ],
      "metadata": {
        "id": "TxGo-Xcsd6wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_map)\n",
        "train_dataset = parsed_train_dataset.map(convert_labels)\n",
        "test_dataset = parsed_test_dataset.map(convert_labels)\n",
        "validation_dataset = parsed_validation_dataset.map(convert_labels)"
      ],
      "metadata": {
        "id": "QHV7S1LWgjB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "shuffle_buffer = 1000\n",
        "\n",
        "preprocessed_train_dataset = parsed_train_dataset.shuffle(shuffle_buffer).batch(batch_size)\n",
        "preprocessed_test_dataset = parsed_test_dataset.batch(batch_size)\n",
        "preprocessed_validation_dataset = parsed_validation_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "KgAKZTujeZ4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(preprocessed_train_dataset,\n",
        "          steps_per_epoch=100,\n",
        "          epochs=50,\n",
        "          validation_data=preprocessed_validation_dataset,\n",
        "          validation_steps=50)"
      ],
      "metadata": {
        "id": "Xx1d3AeWegsl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}